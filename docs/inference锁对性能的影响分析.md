# Inference 函数中的锁对性能影响分析

## 1. 问题背景

在 `rknn::Model::inference()` 函数中添加了互斥锁保护：

```cpp
rknn::ModelResult rknn::Model::inference(cv::Mat img) {
    std::lock_guard<std::mutex> lock(m_inferenceMtx);  // 这个锁会影响性能吗？

    // ... 推理代码 ...

    return m_result;
}
```

**问题**：
- 这个锁会不会影响推理性能？
- 最终推理过程会不会变成单线程推理？

---

## 2. 答案：不会影响多核并行性能

### 2.1 关键点：锁是实例级别的，不是全局锁

```cpp
class Model {
protected:
    std::mutex m_inferenceMtx;  // 每个 Model 对象都有自己独立的锁
};
```

每个模型实例拥有**独立的互斥锁**，而不是所有模型共享一把锁。

### 2.2 当前架构图解

```
┌─────────────────────────────────────────────────────────────────────┐
│                      RknnPool (3个模型实例)                          │
│                                                                     │
│  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐   │
│  │    Model 0      │   │    Model 1      │   │    Model 2      │   │
│  │   (NPU Core 0)  │   │   (NPU Core 1)  │   │   (NPU Core 2)  │   │
│  │                 │   │                 │   │                 │   │
│  │ m_inferenceMtx  │   │ m_inferenceMtx  │   │ m_inferenceMtx  │   │
│  │     (锁 A)      │   │     (锁 B)      │   │     (锁 C)      │   │
│  └────────┬────────┘   └────────┬────────┘   └────────┬────────┘   │
│           │                     │                     │             │
│           ▼                     ▼                     ▼             │
│       线程1执行             线程2执行             线程3执行          │
│       (并行！)              (并行！)              (并行！)          │
│                                                                     │
│              三把锁互不干扰，三个线程真正并行执行                      │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. 为什么不会影响性能？

### 3.1 最优配置下的执行流程

当前配置：**3线程 + 3模型 + 3NPU核心**

```
时间线 →

线程1 (Model0): [获取锁A] ════════════ 推理 ════════════ [释放锁A]
线程2 (Model1): [获取锁B] ════════════ 推理 ════════════ [释放锁B]
线程3 (Model2): [获取锁C] ════════════ 推理 ════════════ [释放锁C]
                ↑
                │
        三个线程同时在推理
        三把锁可以同时持有
        真正的3路并行！
```

### 3.2 锁的独立性

| 线程 | 访问的模型 | 获取的锁 | 是否阻塞 |
|------|-----------|---------|---------|
| 线程1 | Model 0 | 锁 A | 否 |
| 线程2 | Model 1 | 锁 B | 否 |
| 线程3 | Model 2 | 锁 C | 否 |

**关键理解**：
- 锁 A、锁 B、锁 C 是**完全独立的对象**
- 获取锁 A 不影响其他线程获取锁 B 或锁 C
- 三个线程可以**同时**执行推理

---

## 4. 什么情况下锁会造成等待？

### 4.1 场景：多个线程访问同一个模型实例

当线程数 > 模型数时（不推荐的配置）：

```
配置：6个线程，3个模型

┌─────────────────────────────────────────────────────────────────┐
│  Model 0        │  Model 1        │  Model 2                    │
│  ┌───────────┐  │  ┌───────────┐  │  ┌───────────┐              │
│  │   锁 A    │  │  │   锁 B    │  │  │   锁 C    │              │
│  └───────────┘  │  └───────────┘  │  └───────────┘              │
│       ↑↑        │       ↑↑        │       ↑↑                    │
│   线程1 线程4   │   线程2 线程5   │   线程3 线程6               │
│   (竞争!)       │   (竞争!)       │   (竞争!)                   │
└─────────────────────────────────────────────────────────────────┘
```

执行时间线：

```
线程1 (Model0): [获取锁A] ════════ 推理 ════════ [释放锁A]
线程4 (Model0): [等待锁A......................]  [获取锁A] ════ 推理 ════
                      ↑
                 这里才会阻塞！
                 因为线程1和线程4竞争同一把锁
```

### 4.2 阻塞发生的条件

| 条件 | 是否阻塞 |
|------|---------|
| 不同线程访问不同模型 | ❌ 不阻塞 |
| 同一线程访问同一模型 | ❌ 不阻塞（顺序执行） |
| **不同线程访问同一模型** | ✅ **会阻塞** |

---

## 5. 最优配置原则

### 5.1 配置公式

```
线程数 = 模型数 = NPU核心数 = 3
```

### 5.2 各配置对比

| 配置 | 线程数 | 模型数 | 锁等待情况 | 并行度 | 建议 |
|------|--------|--------|-----------|--------|------|
| **最优** | 3 | 3 | 无等待 | 3路并行 | ✅ 推荐 |
| 过多线程 | 6 | 3 | 有等待 | 仍是3路并行 | ❌ 浪费 |
| 过少 | 1 | 1 | 无等待 | 1路串行 | ❌ 未充分利用 |

### 5.3 为什么3线程3模型最优？

```
┌─────────────────────────────────────────────────────────────────┐
│                         最优配置                                 │
│                                                                 │
│   线程1 ←──1:1──→ Model0 ←──1:1──→ NPU Core 0                   │
│   线程2 ←──1:1──→ Model1 ←──1:1──→ NPU Core 1                   │
│   线程3 ←──1:1──→ Model2 ←──1:1──→ NPU Core 2                   │
│                                                                 │
│   特点：                                                         │
│   - 每个线程专属一个模型                                          │
│   - 每个模型绑定一个NPU核心                                       │
│   - 锁永远不会造成等待                                            │
│   - 真正的3路并行推理                                             │
└─────────────────────────────────────────────────────────────────┘
```

---

## 6. 锁的必要性

### 6.1 为什么还需要锁？

即使在最优配置下，锁仍然是必要的，原因如下：

#### (1) 防御性编程

```cpp
// RknnPool 的任务分配
int modelId = getModelId();  // 轮询分配：0, 1, 2, 0, 1, 2, ...
m_pool->submit(&rknnModel::infer, m_models[modelId], inputData);
```

虽然设计上是轮询分配，但如果：
- 某个模型处理较慢
- 任务提交速度很快
- 线程池调度不均匀

可能出现同一模型被多个线程同时访问的情况。

#### (2) 代码健壮性

```cpp
// 即使配置不当，程序也不会崩溃
int thread_num = 6;  // 用户错误地使用了6个线程
rknn::RknnPool<...> pool(model_path, thread_num, ...);

// 有锁保护：程序正常运行，只是性能不是最优
// 无锁保护：可能出现段错误、数据竞争
```

#### (3) 未来扩展

如果以后修改任务分配策略（如负载均衡），锁可以确保线程安全。

### 6.2 锁的开销

```
┌─────────────────────────────────────────────────────────────┐
│                     锁的开销分析                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  无竞争时的 mutex 开销：约 20-50 纳秒                        │
│  单次 NPU 推理耗时：约 20-30 毫秒                            │
│                                                             │
│  比例：锁开销 / 推理耗时 ≈ 0.0001%                          │
│                                                             │
│  结论：锁的开销可以忽略不计                                   │
└─────────────────────────────────────────────────────────────┘
```

---

## 7. 性能验证方法

### 7.1 测试代码

```cpp
void benchmark_inference(const std::string& model_path, const std::string& img_path) {
    cv::Mat img = cv::imread(img_path);
    detector::DetectParam detect_param = {0.25, 0.45, 114, 80};

    // 创建线程池（3线程3模型）
    rknn::RknnPool<detector::YOLO11, cv::Mat, object_detect_result_list> pool(
        model_path, 3, logger::Level::INFO, detect_param);

    const int TEST_COUNT = 100;

    auto start = std::chrono::high_resolution_clock::now();

    // 提交任务
    for (int i = 0; i < TEST_COUNT; i++) {
        pool.put(img);
    }

    // 获取结果
    object_detect_result_list result;
    for (int i = 0; i < TEST_COUNT; i++) {
        pool.get(result);
    }

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    std::cout << TEST_COUNT << " 次推理总耗时: " << duration.count() << " ms" << std::endl;
    std::cout << "平均每次推理: " << duration.count() / TEST_COUNT << " ms" << std::endl;
    std::cout << "吞吐量: " << TEST_COUNT * 1000.0 / duration.count() << " FPS" << std::endl;
}
```

### 7.2 预期结果

| 配置 | 100次推理耗时 | 吞吐量 |
|------|-------------|--------|
| 1线程1模型 | ~3000ms | ~33 FPS |
| 2线程2模型 | ~1500ms | ~66 FPS |
| **3线程3模型** | **~1000ms** | **~100 FPS** |
| 6线程3模型 | ~1000ms | ~100 FPS（无提升） |

---

## 8. 对比：全局锁 vs 实例锁

### 8.1 如果使用全局锁（错误设计）

```cpp
// 错误示例：全局锁
static std::mutex g_globalMtx;  // 所有模型共享一把锁

rknn::ModelResult rknn::Model::inference(cv::Mat img) {
    std::lock_guard<std::mutex> lock(g_globalMtx);  // 全局锁！
    // ...
}
```

执行流程：

```
时间线 →

线程1: [获取全局锁] ════ 推理 ════ [释放]
线程2: [等待..................]  [获取] ════ 推理 ════ [释放]
线程3: [等待..................................]  [获取] ════ 推理 ════
                                                    ↑
                                            变成串行执行！
```

**这才是会影响性能的设计！**

### 8.2 当前设计：实例锁（正确设计）

```cpp
// 正确示例：实例锁
class Model {
    std::mutex m_inferenceMtx;  // 每个实例独立的锁
};

rknn::ModelResult rknn::Model::inference(cv::Mat img) {
    std::lock_guard<std::mutex> lock(m_inferenceMtx);  // 实例锁
    // ...
}
```

执行流程：

```
时间线 →

线程1 (锁A): [获取] ════════════ 推理 ════════════ [释放]
线程2 (锁B): [获取] ════════════ 推理 ════════════ [释放]
线程3 (锁C): [获取] ════════════ 推理 ════════════ [释放]
             ↑
      三路真正并行！
```

---

## 9. 总结

### 9.1 核心结论

| 问题 | 答案 |
|------|------|
| 锁会影响推理性能吗？ | 在最优配置(3线程3模型)下，**不会** |
| 推理会变成单线程吗？ | **不会**，是真正的3路并行 |
| 锁的作用是什么？ | 保护**同一模型实例**不被并发访问 |
| 为什么不影响性能？ | 每个模型有**独立的锁**，3把锁可以**同时持有** |
| 锁有必要吗？ | **有必要**，防御性编程，确保代码健壮 |

### 9.2 记忆要点

```
┌─────────────────────────────────────────────────────────────┐
│                        关键理解                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 实例锁 ≠ 全局锁                                          │
│     - 全局锁：所有线程竞争，串行执行                          │
│     - 实例锁：每个对象独立，可以并行                          │
│                                                             │
│  2. 最优配置：线程数 = 模型数 = NPU核心数                     │
│     - 此时每个线程专属一个模型                                │
│     - 锁永远不会造成等待                                      │
│                                                             │
│  3. 锁的开销可忽略                                           │
│     - 无竞争时：~50纳秒                                       │
│     - 推理耗时：~20毫秒                                       │
│     - 比例：0.0001%                                          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 9.3 最终架构图

```
┌─────────────────────────────────────────────────────────────────────┐
│                      RknnPool 多核推理架构                           │
│                                                                     │
│  ┌───────────┐     ┌───────────┐     ┌───────────┐                 │
│  │  线程 1   │     │  线程 2   │     │  线程 3   │                 │
│  └─────┬─────┘     └─────┬─────┘     └─────┬─────┘                 │
│        │                 │                 │                        │
│        ▼                 ▼                 ▼                        │
│  ┌───────────┐     ┌───────────┐     ┌───────────┐                 │
│  │  Model 0  │     │  Model 1  │     │  Model 2  │                 │
│  │  ┌─────┐  │     │  ┌─────┐  │     │  ┌─────┐  │                 │
│  │  │锁 A │  │     │  │锁 B │  │     │  │锁 C │  │  ← 独立的锁     │
│  │  └─────┘  │     │  └─────┘  │     │  └─────┘  │                 │
│  └─────┬─────┘     └─────┬─────┘     └─────┬─────┘                 │
│        │                 │                 │                        │
│        ▼                 ▼                 ▼                        │
│  ┌───────────┐     ┌───────────┐     ┌───────────┐                 │
│  │NPU Core 0 │     │NPU Core 1 │     │NPU Core 2 │  ← 真正并行     │
│  └───────────┘     └───────────┘     └───────────┘                 │
│                                                                     │
│              三路并行推理，锁不会造成任何性能损失                      │
└─────────────────────────────────────────────────────────────────────┘
```
