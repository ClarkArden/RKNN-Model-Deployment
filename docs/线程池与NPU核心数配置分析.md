# RK3588 线程池与NPU核心数配置分析

## 1. 当前架构

RK3588 芯片拥有 **3个NPU核心**，本项目采用的架构是：

```
┌─────────────────────────────────────────────────────────────┐
│                      RknnPool (3线程)                        │
│                                                             │
│  线程1 ──→ Model0 ──→ NPU Core 0 ──→ 推理                   │
│  线程2 ──→ Model1 ──→ NPU Core 1 ──→ 推理                   │
│  线程3 ──→ Model2 ──→ NPU Core 2 ──→ 推理                   │
│                                                             │
│  每个线程对应一个模型实例，每个模型绑定一个NPU核心            │
└─────────────────────────────────────────────────────────────┘
```

**设计原则**：线程数 = 模型数 = NPU核心数 = 3

---

## 2. 能否使用超过3个线程？

### 技术上：可以

代码层面没有限制，可以创建任意数量的线程和模型实例。

### 实际效果：不推荐

因为硬件资源（NPU核心数）是固定的，超过3个线程无法带来性能提升。

---

## 3. 超过3线程的场景分析

### 场景一：线程数 > 模型数（例如6线程，3模型）

```
┌────────────────────────────────────────────────────────┐
│                    任务队列                             │
│  [img1] [img2] [img3] [img4] [img5] [img6] ...        │
└────────────────────────────────────────────────────────┘
                         │
     ┌───────────────────┼───────────────────┐
     ▼                   ▼                   ▼
┌─────────┐         ┌─────────┐         ┌─────────┐
│ Model0  │         │ Model1  │         │ Model2  │
│ NPU_0   │         │ NPU_1   │         │ NPU_2   │
│         │         │         │         │         │
│ 线程1 ──┼─→ 执行  │ 线程3 ──┼─→ 执行  │ 线程5 ──┼─→ 执行
│ 线程2 ──┼─→ 等锁  │ 线程4 ──┼─→ 等锁  │ 线程6 ──┼─→ 等锁
└─────────┘         └─────────┘         └─────────┘
```

**问题分析**：

```cpp
// Model::inference() 中有互斥锁保护
rknn::ModelResult rknn::Model::inference(cv::Mat img) {
    std::lock_guard<std::mutex> lock(m_inferenceMtx);  // 同一时间只有一个线程能进入
    // ... 推理代码 ...
}
```

- 多个线程竞争同一个模型实例
- 由于互斥锁，同一时间只有一个线程能执行推理
- 额外的线程只是在等待锁，**浪费资源**

**结论**：线程数 > 模型数时，额外线程无意义

---

### 场景二：线程数 = 模型数 > 3（例如6线程，6模型）

```
┌─────────────────────────────────────────────────────────────────┐
│  线程1 ──→ Model0 ──→ NPU Core 0 ──→ 推理                       │
│  线程2 ──→ Model1 ──→ NPU Core 1 ──→ 推理                       │
│  线程3 ──→ Model2 ──→ NPU Core 2 ──→ 推理                       │
│  线程4 ──→ Model3 ──→ NPU Core 0 ──→ 排队等待 Core 0 空闲       │
│  线程5 ──→ Model4 ──→ NPU Core 1 ──→ 排队等待 Core 1 空闲       │
│  线程6 ──→ Model5 ──→ NPU Core 2 ──→ 排队等待 Core 2 空闲       │
└─────────────────────────────────────────────────────────────────┘
```

**核心分配机制**：

```cpp
// rknn_model.hpp 中的核心分配
inline int get_core_num() {
    static int core_num = 0;
    static std::mutex mtx;
    std::lock_guard<std::mutex> lock(mtx);
    int temp = core_num % RK3588_NPU_CORE_NUM;  // 对3取模
    core_num++;
    return temp;  // 返回 0, 1, 2, 0, 1, 2, ...
}
```

| 模型 | 分配的核心 |
|------|-----------|
| Model0 | NPU Core 0 |
| Model1 | NPU Core 1 |
| Model2 | NPU Core 2 |
| Model3 | NPU Core 0 (重复) |
| Model4 | NPU Core 1 (重复) |
| Model5 | NPU Core 2 (重复) |

**问题分析**：

- RK3588 只有3个NPU核心
- 多个模型绑定到同一核心时，会在NPU层面排队
- 没有真正的并行，只是调度开销增加
- 每个模型实例占用内存，**内存浪费**

**结论**：模型数 > NPU核心数时，无法获得更多并行度

---

## 4. 不同配置对比

| 配置 | 线程数 | 模型数 | NPU利用情况 | 效果 | 建议 |
|------|--------|--------|-------------|------|------|
| **最优** | 3 | 3 | 3核完全并行 | 最佳性能 | ✅ 推荐 |
| 过多线程 | 6 | 3 | 线程等待互斥锁 | 资源浪费 | ❌ 不推荐 |
| 过多模型 | 6 | 6 | NPU核心排队 | 内存浪费 | ❌ 不推荐 |
| 过少 | 1 | 1 | 只用1个核心 | 性能低下 | ❌ 不推荐 |
| 较少 | 2 | 2 | 只用2个核心 | 性能一般 | ⚠️ 可用 |

---

## 5. 性能瓶颈分析

### 当前推理流程

```
单次推理流程：
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  预处理     │ →  │  NPU推理    │ →  │  后处理     │
│  (CPU)      │    │  (NPU)      │    │  (CPU)      │
│  ~10ms      │    │  ~20ms      │    │  ~10ms      │
└─────────────┘    └─────────────┘    └─────────────┘
```

### 瓶颈位置

| 阶段 | 执行设备 | 是否可并行 |
|------|----------|-----------|
| 预处理 | CPU | 可以（多核CPU） |
| NPU推理 | NPU | 最多3路并行 |
| 后处理 | CPU | 可以（多核CPU） |

**核心瓶颈**：NPU只有3个核心，这是硬件限制

---

## 6. 什么情况下可以考虑更多线程？

### 6.1 CPU预处理/后处理瓶颈

如果预处理或后处理耗时较长，可以采用**流水线架构**：

```
┌──────────────────┐   ┌──────────────────┐   ┌──────────────────┐
│   预处理线程池    │ → │    NPU推理池     │ → │   后处理线程池    │
│   (N个CPU线程)   │   │   (3个NPU线程)   │   │   (N个CPU线程)   │
└──────────────────┘   └──────────────────┘   └──────────────────┘
        │                      │                      │
   CPU密集型              NPU密集型              CPU密集型
   可用更多线程           固定3线程             可用更多线程
```

### 6.2 多任务类型

如果需要同时运行多种不同的模型（如检测+分类+分割）：

```
┌─────────────────────────────────────────────────────────────┐
│  检测任务池 (1线程) ──→ Model_Det  ──→ NPU Core 0           │
│  分类任务池 (1线程) ──→ Model_Cls  ──→ NPU Core 1           │
│  分割任务池 (1线程) ──→ Model_Seg  ──→ NPU Core 2           │
└─────────────────────────────────────────────────────────────┘
```

---

## 7. 如何修改线程数进行测试？

### 7.1 修改代码

```cpp
// main.cc 中修改线程数测试
void test_thread_pool_yolov5(const std::string& img_path) {
    std::string model_path = "./model/yolov5.rknn";
    detector::DetectParam detect_param = {0.25, 0.45, 114, 80};

    // 修改这里的线程数进行测试
    int thread_num = 6;  // 原来是3，改成6测试

    rknn::RknnPool<detector::YOLO5, cv::Mat, object_detect_result_list> pool(
        model_path, thread_num, logger::Level::INFO, detect_param);

    // ...
}
```

### 7.2 预期结果

| 线程数 | 预期吞吐量 | 原因 |
|--------|-----------|------|
| 1 | ~33 FPS | 只用1个NPU核心 |
| 2 | ~66 FPS | 用2个NPU核心 |
| 3 | ~100 FPS | 用3个NPU核心（最优） |
| 4 | ~100 FPS | 第4个线程等待，无提升 |
| 6 | ~100 FPS | 额外线程等待，无提升 |

---

## 8. 总结

### 核心结论

| 问题 | 答案 |
|------|------|
| 能否使用超过3个线程？ | 技术上可以，但不推荐 |
| 为什么不推荐？ | RK3588只有3个NPU核心，超过3个线程无法并行 |
| 最佳配置是什么？ | **3线程 + 3模型**，一一对应3个NPU核心 |
| 线程越多越好吗？ | **不是**，线程数应匹配硬件资源 |

### 设计原则

```
线程数 ≤ 模型数 ≤ NPU核心数

对于 RK3588：线程数 = 模型数 = 3
```

### 记忆要点

1. **硬件决定上限**：NPU核心数决定了最大并行度
2. **线程不是越多越好**：超过硬件能力只会增加调度开销
3. **资源一一对应**：线程、模型、NPU核心最好一一对应
4. **避免资源浪费**：多余的模型实例会占用内存但不提升性能
